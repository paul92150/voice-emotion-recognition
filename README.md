# ğŸ™ï¸ Voice Emotion Recognition

This project implements a machine learning pipeline to classify **emotions in human voice** using MFCC features extracted from audio recordings.

It supports multiple models (SVM, Logistic Regression) and provides tools for feature selection (Mutual Information), hyperparameter tuning, and AutoML experiments (TPOT, H2O).

---

## ğŸš€ Features

- ğŸ§ MFCC feature extraction using Librosa  
- ğŸ“Š Feature selection (Mutual Information)  
- ğŸ” Grid Search with cross-validation for SVM  
- ğŸ¤– AutoML with TPOT and H2O  
- ğŸ“ˆ Model evaluation with precision, recall, F1-score  
- ğŸ“ Modular and organized codebase (no notebooks!)  
- âœ… Clean training/testing split and preprocessing  

---

## ğŸ—‚ï¸ Project Structure

```
voice-emotion-recognition/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                â† Place your audio dataset here (ignored by Git)
â”œâ”€â”€ models/                 â† Trained models are saved here
â”œâ”€â”€ scripts/                â† All run scripts (training, grid search, etc.)
â”œâ”€â”€ src/                    â† Core logic (feature extraction, preprocessing...)
â”‚   â”œâ”€â”€ features.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ automl.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ README.md               â† This file
â”œâ”€â”€ requirements.txt        â† Python dependencies
â””â”€â”€ .gitignore              â† Keeps datasets and model files out of Git
```

---

## ğŸ“¦ Installation

1. **Clone the repo**:

```bash
git clone https://github.com/Paul92150/voice-emotion-recognition.git
cd voice-emotion-recognition
```

2. **Create a virtual environment (recommended)**

```bash
python -m venv venv
source venv/bin/activate  # On Windows use: venv\Scripts\activate
```

3. **Install dependencies**:

```bash
pip install -r requirements.txt
```

---

## ğŸ“ Data Setup

This repo assumes your dataset is stored in:

```
data/raw/wav/
```

You can use datasets like:
- **Emo-DB** (Berlin Database of Emotional Speech)
- **CREMA-D**, **RAVDESS**, etc.

> âš ï¸ The `data/raw/wav/` folder is ignored by Git to keep the repo light and personal-data-free.

---

## ğŸ·ï¸ Emotion Label Mapping

This project assumes emotion labels are encoded in the filenames using a known convention (e.g., Emo-DB or CREMA-D).

If you're using Emo-DB, you can use the default mapping:

```python
emotion_mapping = {
    'W': 'anger',
    'L': 'boredom',
    'E': 'disgust',
    'A': 'anxiety',
    'F': 'happiness',
    'T': 'sadness',
    'N': 'neutral'
}
```

ğŸ“Œ **Using a different dataset?** Make sure to update both:
- the `emotion_mapping` dictionary (character â†’ emotion name)
- the `label_position` (index of the label character in filenames)

These are typically defined at the top of each script (e.g., `train_svm.py`, `automl_tpot.py`, etc.).

> âš ï¸ If no mapping is provided or a label is missing from the mapping, the corresponding file will be **skipped** during training.

---

## ğŸ§ª How to Run

### ğŸ§  Train an SVM:

```bash
python scripts/train_svm.py
```

### ğŸ” Run Grid Search for Best SVM Parameters:

```bash
python scripts/grid_search.py
```

### ğŸ¤– Run TPOT AutoML:

```bash
python scripts/automl_tpot.py
```

### ğŸ“Š Analyze MFCCs via Mutual Information:

```bash
python scripts/feature_selection_mi.py
```

---

## ğŸ§  Example Results (TPOT AutoML)

```
Accuracy: 73%
F1-score (macro avg): 0.69
Best pipeline: MinMaxScaler â†’ RFE â†’ XGBoostClassifier
```

ğŸ“Œ The dataset was relatively small, and AutoML reached results comparable to hand-tuned SVM.

---

## ğŸ‘¤ Author

**Paul Lemaire**  
Student at CentraleSupÃ©lec  
[LinkedIn](https://www.linkedin.com/in/paul-lemaire-aa0369289) â€¢ [GitHub](https://github.com/Paul92150)

---

## ğŸ› ï¸ Future Improvements

- ğŸ“¦ Add support for metadata-based emotion labeling (e.g., from CSV)
- ğŸ“Š Add ROC curve visualizations
- ğŸ¯ Integrate more datasets (e.g., RAVDESS, TESS)
- âš™ï¸ Add configuration file (e.g., `config.yaml`) to make scripts more flexible
- ğŸ§ª Add test suite for pipeline robustness

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.
